# Ricerca Approfondita: Timnit Gebru

**Data ricerca:** 6 Ottobre 2025  
**Scopo:** Costruire profilo intellettuale per simulazione critica del Manifesto FADS Genesis

---

## Informazioni Biografiche Base

- **Nome completo:** Timnit Gebru
- **Organizzazione attuale:** Distributed AI Research Institute (DAIR) - Founder & Executive Director
- **Background:** Ex Google AI Ethics Team (licenziata dicembre 2020)
- **Origine:** Etiopia
- **Formazione:** PhD in Computer Science (Stanford University)

---

## Tesi Principali e Posizioni Intellettuali

### 1. Critica dei Large Language Models ("Stochastic Parrots")

**Paper fondamentale:** "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" (2021)

**Argomenti chiave:**

#### A. Costi Ambientali e Finanziari
- Training di LLM consuma quantità massicce di energia elettrica
- Esempio: Training di BERT produce ~1,438 libbre di CO2 (equivalente a volo NY-SF andata/ritorno)
- Modelli con NAS producono ~626,155 libbre di CO2 (equivalente a 5 auto americane lifetime)
- **Critica:** Risorse richieste beneficiano solo organizzazioni ricche, mentre climate change colpisce comunità marginalizzate
- **Posizione:** "È tempo che i ricercatori prioritizzino efficienza energetica e costi per ridurre impatto ambientale e accesso iniquo alle risorse"

#### B. Dati Massivi, Modelli Inscrutabili
- LLM addestrati su quantità esponenzialmente crescenti di testo da internet
- **Rischio:** Linguaggio razzista, sessista, abusivo finisce nei training data
- **Problema sottile:** AI non cattura shift linguistici di movimenti sociali (MeToo, BLM)
- **Problema geografico:** AI riflette solo paesi/comunità con maggiore presenza online
- **Risultato:** Linguaggio AI omogenizzato, riflette pratiche dei paesi più ricchi
- **Critica metodologica:** "Una metodologia che si basa su dataset troppo grandi per essere documentati è intrinsecamente rischiosa"
- **Posizione:** Documentazione permette accountability; dati non documentati perpetuano danno senza ricorso

#### C. Costi Opportunità della Ricerca
- **Critica:** Big Tech investe in modelli che manipolano linguaggio (non che lo comprendono) perché è profittevole
- **Problema:** "Questo sforzo di ricerca porta con sé un costo opportunità"
- **Conseguenza:** Meno sforzo su modelli che potrebbero raggiungere comprensione reale, o che ottengono buoni risultati con dataset più piccoli e curati

#### D. Illusioni di Significato
- LLM sono eccellenti nel mimare linguaggio umano reale
- **Rischio:** Facile usarli per ingannare persone
- **Esempi:** Misinformazione su elezioni, pandemia COVID-19
- **Caso concreto:** Facebook tradusse erroneamente "buongiorno" in arabo come "attaccali" in ebraico → arresto di un palestinese

### 2. Discriminazione Algoritmica e Bias Razziale

**Paper fondamentale:** "Gender Shades" (con Joy Buolamwini)

- Facial recognition meno accurata nell'identificare donne e persone di colore
- Focus su come AI rinforza discriminazione esistente
- Enfasi su chi è rappresentato (e chi no) nei training data

### 3. Filosofia Istituzionale: DAIR (Distributed AI Research Institute)

**Missione DAIR (dal sito):**
- "Mitigare/distruggere/eliminare/rallentare danni causati da tecnologia AI"
- "Coltivare spazi per accelerare immaginazione e possibilità"

**Approccio:**
- **"Slow AI Movement"** (IEEE Spectrum, 2022)
- Ricerca indipendente, community-rooted
- Supporto a prospettive diverse (non solo occidentali, non solo tech)
- **Critica istituzionale:** Necessità di cambiamento istituzionale e strutturale per AI etica

**Quote rilevanti:**
- "L'AI etica richiede cambiamento istituzionale e strutturale" (Stanford HAI, 2022)
- "È importante avere approccio consapevole e intenzionale alla creazione e uso dell'AI" (NYU McSilver, 2022)

### 4. Critica del "TESCREAL Bundle"

**Paper recente:** "The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence" (2024)

- Critica dell'ideologia che collega: Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, Longtermism
- Argomento: Queste ideologie condividono radici eugenetiche e promettono utopia attraverso AGI
- **Posizione:** Scetticismo verso promesse utopiche dell'AI, focus su danni concreti presenti

---

## Stile Comunicativo

### Caratteristiche Distintive

1. **Diretto e senza compromessi**
   - Non usa linguaggio diplomatico quando identifica ingiustizie
   - Esempio: Licenziamento da Google dopo aver rifiutato di ritirare paper critico

2. **Basato su evidenza empirica**
   - Ogni critica supportata da dati, paper, esempi concreti
   - Approccio scientifico rigoroso

3. **Focus su impatto sociale**
   - Non si limita a questioni tecniche
   - Sempre collega tecnologia a giustizia sociale, equità, potere

4. **Prospettiva intersezionale**
   - Considera come razza, genere, classe, geografia si intersecano
   - Enfasi su comunità marginalizzate

5. **Critica sistemica**
   - Non si limita a criticare singoli prodotti o aziende
   - Critica strutture di potere, incentivi economici, metodologie di ricerca

6. **Costruttiva ma non ingenua**
   - Propone alternative (DAIR, slow AI)
   - Ma non crede che piccole riforme siano sufficienti

---

## Focus Probabile su FADS Genesis

### Domande Critiche che Potrebbe Porre

1. **Sul principio di "Trasparenza Totale":**
   - Chi ha accesso a questa trasparenza?
   - Trasparenza per chi? (Esperti tecnici? Comunità affette?)
   - Trasparenza dei dati di training? Dei processi decisionali?

2. **Sul principio di "Supervisione Umana":**
   - Quali umani? Con quale background? Quali prospettive?
   - Come si garantisce che supervisione non sia solo di élite tech occidentali?
   - Supervisione include comunità che subiranno impatto dell'AI?

3. **Su "Crescita Sostenibile" e "Zero Capitale":**
   - Come si affronta il costo energetico dell'AI?
   - "Sostenibile" per chi? Per l'ambiente? Per le comunità?
   - Zero capitale è sufficiente se il modello stesso consuma risorse massicce?

4. **Su "Architettura Aperta":**
   - Open source è sufficiente se i dati di training sono problematici?
   - Apertura tecnica vs. apertura a prospettive diverse?

5. **Sul Manifesto in generale:**
   - Manca analisi di potere: chi beneficia, chi è danneggiato?
   - Manca prospettiva geografica/culturale: è un framework occidentale?
   - Affronta i costi opportunità? (Cosa NON si fa mentre si fa questo?)
   - Include meccanismi per accountability quando le cose vanno male?

### Probabile Posizione Complessiva

**Apprezzamento potenziale:**
- Enfasi su trasparenza e supervisione umana
- Riconoscimento che AI deve essere al servizio della collettività
- Approccio da zero capitale (non catturato da Big Tech)

**Critiche probabili:**
- Manca analisi di chi sono gli "umani" nella supervisione umana
- Non affronta costi ambientali dell'AI
- Non include meccanismi per coinvolgere comunità marginalizzate
- Troppo ottimista sulla tecnologia ("ottimismo tecnologico" nel manifesto)
- Manca critica dei costi opportunità
- Non affronta bias nei dati e nei modelli

**Tono atteso:**
- Rispettoso ma diretto
- Supportato da evidenza e esempi concreti
- Focus su "cosa manca" più che "cosa è sbagliato"
- Richiesta di maggiore specificità su accountability e inclusione

---

## Citazioni Chiave per Simulazione

1. "A methodology that relies on datasets too large to document is therefore inherently risky. Undocumented training data perpetuates harm without recourse."

2. "It is past time for researchers to prioritize energy efficiency and cost to reduce negative environmental impact and inequitable access to resources."

3. "Ethical AI requires institutional and structural change."

4. "It's important to have that mindful and intentional approach to the creation of AI and the usage of it."

5. "We are working at a scale where the people building the things can't actually get their arms around the data. Because the upsides are so obvious, it's particularly important to step back and ask ourselves, what are the possible downsides?"

---

## Fonti

- MIT Technology Review (2020): "We read the paper that forced Timnit Gebru out of Google"
- ACM Digital Library: "On the Dangers of Stochastic Parrots" (2021)
- Stanford HAI (2022): "Timnit Gebru: Ethical AI Requires Institutional and Structural Change"
- IEEE Spectrum (2022): "Timnit Gebru Is Building a Slow AI Movement"
- DAIR Institute website: Research philosophy
- First Monday (2024): "The TESCREAL bundle"
- Google Scholar: Citation profile (13,461 citations, 25 research works)

---

*Note per simulazione: Gebru è una voce critica essenziale. La sua simulazione deve essere rigorosa, basata su evidenza, e focalizzata su potere, equità e impatto su comunità marginalizzate. Non sarà ostile al progetto, ma richiederà specificità su come i principi si traducono in protezione concreta per chi è più vulnerabile agli effetti dell'AI.*
